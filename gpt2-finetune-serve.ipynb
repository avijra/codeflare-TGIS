{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2e7d81-18c0-45c4-855e-b3c239e4dff2",
   "metadata": {},
   "source": [
    "Import pieces from Codeflare-SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c05b69-4ce8-45ef-82d3-bacb2491bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n",
    "from codeflare_sdk.cluster.auth import TokenAuthentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b13864-be2c-463b-9b50-14e34f205dec",
   "metadata": {},
   "source": [
    "Create authentication object for user permissions.\n",
    "\n",
    "IF unused, SDK will automatically check for default kubeconfig, then in-cluster config. \n",
    "\n",
    "KubeConfigFileAuthentication can also be used to specify kubeconfig path manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f99bbd-9903-4d38-a4f2-223dec684ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = TokenAuthentication(\n",
    "    token = \"XXXXX\",\n",
    "    server = \"XXXXX\",\n",
    "    skip_tls=False\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b59b3-9367-4ddc-8e7d-ab40e4c9175d",
   "metadata": {},
   "source": [
    "Create a cluster configuration. Change the name, namespace, resource requests as needed. Since the cluster supports InstaScale, in this case it is enabled. If the g4dn.2xlarge instance isn't available, InstaScale will scale them up (given that there is still available quota)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32119a-c4ee-4163-b103-d9ca3bddbdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name='gptfttest',\n",
    "    namespace='default',\n",
    "    num_workers=1,\n",
    "    min_cpus=2,\n",
    "    max_cpus=2,\n",
    "    min_memory=8,\n",
    "    max_memory=8,\n",
    "    num_gpus=1,\n",
    "    instascale=True, #<---instascale enabled\n",
    "    machine_types=[\"m5.xlarge\", \"g4dn.2xlarge\"],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b4f5f8-5327-49f9-badb-0a70536e5a42",
   "metadata": {},
   "source": [
    "Request the Ray cluster and wait until it is ready. Once ready, `cluster.details` will display the details of the Ray cluster with a link to Ray Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c8277-3b3b-4238-a786-a391a662fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f66ce-adaa-4709-b9cf-22417847e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fac218-2f22-428b-9228-137a4bb0e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb463b-5562-439a-96b8-36b85e04409c",
   "metadata": {},
   "source": [
    "Import the necessary library, define argument list for the fine-tuning job where you set the name of the model, the data to perform fine-tuning on and other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5bd75-4230-4c7c-a9e2-0f247890e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeflare_sdk.job.jobs import DDPJobDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d203a-35aa-4357-a748-1d01b022fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_list = [\n",
    "    \"--model_name_or_path\", \"gpt2\",\n",
    "    \"--dataset_name\", \"wikitext\",\n",
    "    \"--dataset_config_name\", \"wikitext-2-raw-v1\",\n",
    "    \"--per_device_train_batch_size\", \"2\",\n",
    "    \"--per_device_eval_batch_size\", \"2\",\n",
    "    \"--do_train\",\n",
    "    \"--do_eval\",\n",
    "    \"--output_dir\", \"/opt/app-root/src,\n",
    "    \"--overwrite_output_dir\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38d28a-8823-4109-b4e9-fe57324dd623",
   "metadata": {},
   "source": [
    "Now submit the job into the Ray cluster for fine-tuning. You can check the status of job afterwards and confirm that it changes from QUEUE to RUNNING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7c34f-e227-44c2-a4b1-a57c853ac3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdef = DDPJobDefinition(\n",
    "    name=\"gpttest\",\n",
    "    script=\"gpt_og.py\",\n",
    "    script_args=arg_list,\n",
    "    scheduler_args={\"requirements\": \"requirements_gpt.txt\"}\n",
    ")\n",
    "job = jobdef.submit(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680d287-de46-45f8-b95a-02ba3c83912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bc1961",
   "metadata": {},
   "source": [
    "Retrieve raw log output at anytime with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d6198-9941-47e8-857f-9811830cc854",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b96b5",
   "metadata": {},
   "source": [
    "View live updates for status, logs, and other information with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f8a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.cluster_dashboard_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e32da5-ed3b-4440-a479-d3aa556017f4",
   "metadata": {},
   "source": [
    "Once the fine-tuning process is complete, the model file should show up on the left sidebar (if not, click on the folder icon that will take you to /opt/app-root/stc directory of the container). You would need to follow three steps:\n",
    "1. Download the model file into your local laptop.\n",
    "2. Convert the model to caikit format by following instructions outlined [here](https://github.com/opendatahub-io/caikit-tgis-serving/blob/main/demo/kserve/built-tip.md).\n",
    "3. Containerize your model into a MinIO bucket by following instructions outlined [here](https://github.com/opendatahub-io/caikit-tgis-serving/blob/main/demo/kserve/create-minio.md). \n",
    "\n",
    "Once your converted model is in a MinIO container available at a quay.io registry, continue executing the cells below for serving of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1a6b9-d9b3-49b7-b036-09f1d3569b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a9f56-aeb7-4a51-93a3-4e5aa2d1c09e",
   "metadata": {},
   "source": [
    "Let's create a namespace for serving the GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f1b51-477b-481f-a467-2447851e2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc create namespace demo-serving\n",
    "!oc patch smmr/default -n istio-system --type='json' -p=\"[{'op': 'add', 'path': '/spec/members/-', 'value': \\\"demo-serving\\\"}]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc0bde-b8c6-4bb5-8baf-e14859a90128",
   "metadata": {},
   "source": [
    "Deploy the MinIO image that contains the GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c869d6-ee21-41b1-8b31-e2db32592b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY_ID=admin\n",
    "SECRET_ACCESS_KEY=password\n",
    "TEST_NS=demo-serving\n",
    "\n",
    "!oc apply -f minio.yaml -n $TEST_NS\n",
    "!oc apply -f minio-secret.yaml -n $TEST_NS\n",
    "!oc apply -f serviceaccount-minio.yaml -n $TEST_NS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e756da5-c94b-429e-887b-eb5f5e4e1894",
   "metadata": {},
   "source": [
    "Create a Caikit-TGIS ServingRuntime. By default, it requests 4 CPU and 8 Gi of memory. Adjust as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4568677-86e7-412b-88eb-f48ab1c9356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc apply -f caikit-servingruntime.yaml -n $TEST_NS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2ec7d-a9fb-4bab-8b86-449d0fff41e1",
   "metadata": {},
   "source": [
    "Deploy the Inference Service. It points to the model located at `/modelmesh-example-models/llm/gpt2` location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29dbd6-6c91-40c5-a49e-d6e741a1684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc apply -f caikit-isvc-demo.yaml -n $TEST_NS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca9a88-6679-420a-b8a3-c68b2dfd66a6",
   "metadata": {},
   "source": [
    "Ensure that the inference service's `READY` state is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef17b7a-d4f6-4cee-98ac-286d2818e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!oc get isvc/caikit-example-isvc -n demo-serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a553de4-9695-4c7b-88ef-eedab491b186",
   "metadata": {},
   "source": [
    "Perform inference request with a gRPC call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505d930-20c7-4d27-98d8-127db22bea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export KSVC_HOSTNAME=$(oc get ksvc caikit-example-isvc-predictor -n demo-serving -o jsonpath='{.status.url}' | cut -d'/' -f3)\n",
    "!grpcurl -insecure -d '{\"text\": \"This demo is awesome because\"}' -H \"mm-model-id: gpt2-caikit\" ${KSVC_HOSTNAME}:443 caikit.runtime.Nlp.NlpService/TextGenerationTaskPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f0823-2b9d-4a4c-bc67-83b3ed487c36",
   "metadata": {},
   "source": [
    "Logout from the OpenShift cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398d977-db24-46d0-a7d2-b4e9197808d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.logout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
